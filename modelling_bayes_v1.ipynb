{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22c52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import arviz as az\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pymc3 as pm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.prepare_data import clean_data, filter_rows_by_std, get_magnitude_diffs, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40371a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf370f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = load_data()\n",
    "# load the data\n",
    "df_mex = load_data(filename='mexico_labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4af517",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(df)  # Basic cleaning\n",
    "# construct the magnitude differences\n",
    "ordered_mag_columns = ['magcr3', 'magbr3', 'magar3', 'bpmag', 'gmag', 'rpmag', 'jmag', 'kmag']\n",
    "df_diffs = get_magnitude_diffs(df, ordered_mag_columns)\n",
    "# filter Na's and measurements with too large standard deviations\n",
    "df_diffs_filtered = filter_rows_by_std(df_diffs, df, std_thresholds={\n",
    "    'sigcr3': 0.05,\n",
    "    'sigbr3': 0.05,\n",
    "    'sigar3': 0.05,\n",
    "    'ejmag': 0.05,\n",
    "    'ekmag': 0.05,\n",
    "}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee0c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mex = clean_data(df_mex)  # Basic cleaning\n",
    "# construct the magnitude differences\n",
    "ordered_mag_columns = ['magcr3', 'magbr3', 'magar3', 'bpmag', 'gmag', 'rpmag', 'jmag', 'kmag']\n",
    "df_diffs_mex = get_magnitude_diffs(df_mex, ordered_mag_columns)\n",
    "df_diffs_mex['bpmag_rpmag'] = df_mex['bpmag'] - df_mex['rpmag']\n",
    "# filter Na's and measurements with too large standard deviations\n",
    "df_diffs_filtered_mex = filter_rows_by_std(df_diffs_mex, df_mex, std_thresholds={\n",
    "    'sigcr3': 0.05,\n",
    "    'sigbr3': 0.05,\n",
    "    'sigar3': 0.05,\n",
    "    'ejmag': 0.05,\n",
    "    'ekmag': 0.05,\n",
    "}).dropna()\n",
    "\n",
    "df_diffs_filtered_mex = df_diffs_filtered_mex[\n",
    "    (df_diffs_filtered_mex['magcr3_magbr3']>-50) \n",
    "    * (df_diffs_filtered_mex['magcr3_magbr3']<50)\n",
    "    * (df_diffs_filtered_mex['magbr3_magar3']<50)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db436b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-index\n",
    "df_filter = df.loc[df_diffs_filtered.index]\n",
    "df_mex_filter = df_mex.loc[df_diffs_filtered_mex.index]\n",
    "\n",
    "df_mex_filter.index = df_mex_filter.index + 3000\n",
    "df_diffs_filtered_mex.index = df_diffs_filtered_mex.index + 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298b8c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "df = pd.concat([df_filter, df_mex_filter])\n",
    "df_diffs_filtered = pd.concat([df_diffs_filtered, df_diffs_filtered_mex])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32f3e9",
   "metadata": {},
   "source": [
    "# Bayesian Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb2ee3b",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e88412",
   "metadata": {},
   "source": [
    "WEB references (all with PyMC3):\n",
    "- https://docs.pymc.io/en/v3/pymc-examples/examples/generalized_linear_models/GLM-linear.html\n",
    "- [not-the-most-readable-guide] https://benslack19.github.io/data%20science/statistics/pymc-linreg-entry01/\n",
    "- [check with hack account] https://towardsdatascience.com/bayesian-linear-regression-in-python-via-pymc3-ab8c2c498211\n",
    "- https://vincentk1991.github.io/Bayesian-regression-tutorial/ (a study on different connections among predictors and a target variable)\n",
    "- [with GLM] https://www.quantstart.com/articles/Bayesian-Linear-Regression-Models-with-PyMC3/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1577da58",
   "metadata": {},
   "source": [
    "## Models depending on field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_diffs_filtered\n",
    "\n",
    "giant_indicator = df['logg'][X.index] < 3.5\n",
    "\n",
    "X = X[giant_indicator]\n",
    "\n",
    "fields = df['field'][X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf17bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_value = df['loggflag'][X.index]>.3*10**8\n",
    "# vmicroflag : about 3x bigger error on vmicroflag>100 measurements.\n",
    "# filter_value = df['vmicroflag'][X.index][giant_indicator]>100\n",
    "print(f'Fall out: {sum(filter_value)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c57f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, filter_value.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893afdda",
   "metadata": {},
   "source": [
    "### Magnitude diff shift from 'star-metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict C-B magnitude diff from temperature, gravity and chemistry and fix intercept on the field\n",
    "\n",
    "X_use = df[['logg', 'teff', 'cafe', 'feh']].loc[df_diffs_filtered.index]\n",
    "# replace 'magcr3_magbr3' with 'magbr3_magar3' in the line below\n",
    "y_use = df_diffs_filtered['magbr3_magar3']\n",
    "fields_use = df['field'][df_diffs_filtered.index]\n",
    "\n",
    "giant_indicator = df['logg'][df_diffs_filtered.index] < 3.5\n",
    "filter_value = df['loggflag'][df_diffs_filtered.index]>.3*10**8\n",
    "\n",
    "# Filter!\n",
    "# X_use = X_use[~filter_value]\n",
    "# y_use = y_use[~filter_value]\n",
    "# fields_use = fields_use[~filter_value]\n",
    "\n",
    "ind = X_use.index\n",
    "cols = X_use.columns\n",
    "normalizer = StandardScaler()\n",
    "X_use = normalizer.fit_transform(X_use)\n",
    "X_use = pd.DataFrame(\n",
    "    data=X_use,\n",
    "    index=ind,\n",
    "    columns=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2494e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_use.shape, y_use.shape, fields_use.shape, len(set(fields_use.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b591ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as predictive_model:\n",
    "    a_teff = pm.Normal('slope_teff', 0, 1)\n",
    "    a_logg = pm.Normal('slope_logg', 0, 1)\n",
    "    a_cafe = pm.Normal('slope_cafe', 0, 1)\n",
    "    a_feh = pm.Normal('slope_feh', 0, 1)\n",
    "    \n",
    "    mag_shift = pm.Normal('mag_shift', 0, .1, shape=len(set(fields_use.values)))\n",
    "    eps = pm.Exponential('error', 1)\n",
    "    \n",
    "    # a data container, can be changed\n",
    "    # observation\n",
    "    x_teff = pm.Data('x_teff', X_use['teff'].values)\n",
    "    x_logg = pm.Data('x_logg', X_use['logg'].values)\n",
    "    x_cafe = pm.Data('x_cafe', X_use['cafe'].values)\n",
    "    x_feh = pm.Data('x_feh', X_use['feh'].values)\n",
    "    \n",
    "    field_index = list(set(fields_use))\n",
    "    field_index.sort(key=lambda x: int(x.split('-')[1]))\n",
    "    field_index = {x: e for e, x in enumerate(field_index)}\n",
    "    field = pm.Data('field', [field_index[f] for f in fields_use.values])\n",
    "    \n",
    "    obs = pm.Normal(\n",
    "        'observation',\n",
    "        a_teff * x_teff + a_logg * x_logg + a_cafe * x_cafe + a_feh * x_feh + mag_shift[field],\n",
    "        eps,\n",
    "        observed=y_use\n",
    "    )\n",
    "    \n",
    "    # Use Maximum A Posteriori (MAP) optimisation as initial value for MCMC\n",
    "    start = pm.find_MAP()\n",
    "    # Use the No-U-Turn Sampler\n",
    "    step = pm.NUTS()\n",
    "\n",
    "    # use MCMC to sample\n",
    "    trace = pm.sample(\n",
    "        draws=8000,\n",
    "        tune=1000,\n",
    "        # start=start,\n",
    "        # \n",
    "        return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa16ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace.posterior.mag_shift.values.mean(axis=1).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214026b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_shifts = [(f, shift) for f, shift in\n",
    "              zip(field_index, trace.posterior.mag_shift.values.mean(axis=1).mean(axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6688f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(trace, var_names=['error', 'mag_shift'], grid=(17, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395b928",
   "metadata": {},
   "outputs": [],
   "source": [
    "mag_shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221ca423",
   "metadata": {},
   "source": [
    "### Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c7154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)  # Plot trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check autocorrelation - for all the parameters, for all the chains.\n",
    "az.plot_autocorr(trace)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "242fb8207f97c296f33acf6c366d1e468ec158fb77fc4d51a9c4c6884f3da01a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('p2ch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
