{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b8d2f1",
   "metadata": {},
   "source": [
    "# CaFe relation for giants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c78df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils.prepare_data import clean_data, filter_rows_by_std, get_magnitude_diffs, join_rows_from_raw, load_data\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dc4180",
   "metadata": {},
   "source": [
    "## Prepare the data for the modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e5d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = load_data()\n",
    "target_variable = 'cafe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77732545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data(df)  # Basic cleaning\n",
    "# construct the magnitude differences\n",
    "ordered_mag_columns = ['magcr3', 'magbr3', 'magar3', 'bpmag', 'gmag', 'rpmag', 'jmag', 'kmag']\n",
    "df_diffs = get_magnitude_diffs(df, ordered_mag_columns)\n",
    "df_diffs['bpmag_rpmag'] = df['bpmag'] - df['rpmag']\n",
    "# filter Na's and measurements with too large standard deviations\n",
    "df_diffs_filtered = filter_rows_by_std(df_diffs, df, std_thresholds={\n",
    "    'sigcr3': 0.05,\n",
    "    'sigbr3': 0.05,\n",
    "    'sigar3': 0.05,\n",
    "    'ejmag': 0.05,\n",
    "    'ekmag': 0.05,\n",
    "}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb38508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df_diffs_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc56b9",
   "metadata": {},
   "source": [
    "### Field shifts from Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d54586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cb_field_shift'] = df['field'].map({\n",
    "    'Field-1': 0.3319922760263798,\n",
    "    'Field-2': 0.41525421695893566,\n",
    "    'Field-3': 0.4374036431066466,\n",
    "    'Field-4': 0.41137730050813004,\n",
    "    'Field-5': 0.35876049518667247,\n",
    "    'Field-6': 0.42670825326670114,\n",
    "    'Field-8': 0.4220114380659433,\n",
    "    'Field-9': 0.38748489552795107,\n",
    "    'Field-10': 0.38493277215437155,\n",
    "    'Field-11': 0.3910498880361436,\n",
    "    'Field-15': 0.37523785738068216,\n",
    "    'Field-16': 0.37873686102483073,\n",
    "    'Field-17': 0.37748938994827175,\n",
    "    'Field-18': 0.3650478096668249,\n",
    "    'Field-19': 0.39866733152517186,\n",
    "    'Field-20': 0.39821298519891424,\n",
    "    'Field-24': 0.42353001068319074,\n",
    "    'Field-25': 0.432486767263635,\n",
    "    'Field-27': 0.40814162530040954,\n",
    "    'Field-28': 0.37364547999152314,\n",
    "    'Field-29': 0.4262784749766956,\n",
    "    'Field-32': 0.4809766006917441,\n",
    "    'Field-33': 0.42479356859998646,\n",
    "    'Field-34': 0.4177341235655455,\n",
    "    'Field-35': 0.45922559449923883,\n",
    "    'Field-38': 0.5008953767354531,\n",
    "    'Field-39': 0.3607422231174212,\n",
    "    'Field-40': 0.3808902958085871,\n",
    "    'Field-41': 0.3588893561248595,\n",
    "    'Field-42': 0.36663408584866286,\n",
    "    'Field-45': 0.3572882366819113,\n",
    "    'Field-46': 0.36898328437951294,\n",
    "    'Field-47': 0.40957565746657026,\n",
    "})\n",
    "\n",
    "df['ba_field_shift'] = df['field'].map({\n",
    "    'Field-1': 0.18080835515053956,\n",
    "    'Field-2': 0.19971150768603052,\n",
    "    'Field-3': 0.16673795188561255,\n",
    "    'Field-4': 0.22764694756560977,\n",
    "    'Field-5': 0.16393258009286565,\n",
    "    'Field-6': 0.2218356785159324,\n",
    "    'Field-8': 0.21095491325215732,\n",
    "    'Field-9': 0.19161996881699248,\n",
    "    'Field-10': 0.1837026412942269,\n",
    "    'Field-11': 0.18115561005808317,\n",
    "    'Field-15': 0.15200887755485093,\n",
    "    'Field-16': 0.1656647564454164,\n",
    "    'Field-17': 0.1667862329753091,\n",
    "    'Field-18': 0.13141335282697575,\n",
    "    'Field-19': 0.12365755419411407,\n",
    "    'Field-20': 0.23729289979478213,\n",
    "    'Field-24': 0.15642818357320198,\n",
    "    'Field-25': 0.1840500586940485,\n",
    "    'Field-27': 0.22263591110330505,\n",
    "    'Field-28': 0.14583983959304825,\n",
    "    'Field-29': 0.1633080989641097,\n",
    "    'Field-32': 0.10157314049954563,\n",
    "    'Field-33': 0.1320147960009749,\n",
    "    'Field-34': 0.14638373988925385,\n",
    "    'Field-35': 0.1275999413428845,\n",
    "    'Field-38': 0.12160791831422073,\n",
    "    'Field-39': 0.17665871089194196,\n",
    "    'Field-40': 0.1635198872846553,\n",
    "    'Field-41': 0.2009430095532145,\n",
    "    'Field-42': 0.1866283299753808,\n",
    "    'Field-45': 0.1722000325556393,\n",
    "    'Field-46': 0.15581685616524635,\n",
    "    'Field-47': 0.22921627154498236,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f148e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_diffs_filtered\n",
    "y = df[target_variable][X.index]\n",
    "y_sum = df['cafe'][X.index] + df['feh'][X.index]\n",
    "\n",
    "# giant indicator\n",
    "giant_indicator = df['logg'][X.index] < 3.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce00da7b",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81a4ad",
   "metadata": {},
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967e37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_diffs_filtered[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'bpmag_rpmag']]\n",
    "X = join_rows_from_raw(X, df, ['logg', 'teff'])[giant_indicator]\n",
    "y = df[target_variable][X.index]\n",
    "y_sum = df['cafe'][X.index] + df['feh'][X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RepeatedKFold(n_splits=8, n_repeats=4, random_state=316)\n",
    "\n",
    "# define the pipeline to evaluate\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('normalizer', StandardScaler()),\n",
    "    ('feature_selector', SelectKBest(score_func=mutual_info_regression)),\n",
    "    ('model', MLPRegressor(max_iter=4000))\n",
    "])\n",
    "# With target transform pipeline\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('normalizer', StandardScaler()),\n",
    "#     ('feature_selector', SelectKBest(score_func=mutual_info_regression)),\n",
    "#     ('model', TransformedTargetRegressor(regressor=MLPRegressor(max_iter=4000), transformer=PowerTransformer()))\n",
    "# ])\n",
    "# define the grid : from 1 to all features\n",
    "grid = {\n",
    "    'feature_selector__k': [i for i in range(2, 7)],\n",
    "    'model__hidden_layer_sizes': [(9,), (12,), (16,)],\n",
    "    'model__activation': ['logistic', 'tanh', 'relu'],\n",
    "    'model__solver': [\n",
    "        'lbfgs',\n",
    "        # 'sgd',\n",
    "        # 'adam'\n",
    "    ],\n",
    "    # 'model__regressor__hidden_layer_sizes': [(9,), (12,), (16,)],\n",
    "    # 'model__regressor__activation': ['logistic', 'tanh', 'relu'],\n",
    "    # 'model__regressor__solver': ['lbfgs', 'sgd', 'adam'],\n",
    "}\n",
    "# define the grid search\n",
    "search = GridSearchCV(\n",
    "    pipeline,\n",
    "    grid,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    # verbose=2\n",
    ")\n",
    "# perform the search\n",
    "results = search.fit(X, y)\n",
    "# summarize best\n",
    "print(f'Best nMAE: {results.best_score_:.6f}', )\n",
    "print(f'Best Config: {results.best_params_}:', )\n",
    "\n",
    "print('Feature scores:')\n",
    "for f, sc in zip(X.columns, search.best_estimator_.get_params().get('feature_selector').scores_):\n",
    "    print(f'{f:16s} {sc:.6f}')\n",
    "print(f'Selected features: {list(X.columns[search.best_estimator_.get_params().get(\"feature_selector\").get_support()])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959a033",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = search.predict(X)\n",
    "plt.scatter(y, y_predicted)\n",
    "plt.plot([-.2, .5], [-.2, .5], color='r')\n",
    "print(r2_score(y, y_predicted), mean_absolute_error(y, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd967d3",
   "metadata": {},
   "source": [
    "### Prepare train & test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147345a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_use = df_diffs_filtered[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'bpmag_rpmag']]\n",
    "# X_use = join_rows_from_raw(X_use, df, ['teff', 'logg'])\n",
    "\n",
    "X_use['magcr3_magbr3'] = (X_use['magcr3_magbr3'] - df['cb_field_shift'][X_use.index] + .75)**(1/3)\n",
    "X_use['magbr3_magar3'] = X_use['magbr3_magar3'] - df['ba_field_shift'][X_use.index]\n",
    "X_use['jmag_kmag'] = (X_use['jmag_kmag'])**(1/2)\n",
    "X_use['bpmag_rpmag'] = (X_use['bpmag_rpmag'])**(1/2)\n",
    "\n",
    "'''\n",
    "ind = X_use.index\n",
    "cols = X_use.columns\n",
    "normalizer = StandardScaler()\n",
    "X_use = normalizer.fit_transform(X_use)\n",
    "X_use = pd.DataFrame(\n",
    "    data=X_use,\n",
    "    index=ind,\n",
    "    columns=cols\n",
    ")'''\n",
    "\n",
    "# logg and teff are well predictable from X_use, while CaFe and FeH are pure :/ \n",
    "y_use = y\n",
    "# y_use = np.cbrt(y_use)\n",
    "# y_use = y_use**3\n",
    "\n",
    "X_use = X_use[giant_indicator]\n",
    "y_use = y_use[giant_indicator]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_use, y_use, test_size=0.25, random_state=314)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb5d78f",
   "metadata": {},
   "source": [
    "### Fit models for teff & logg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loggflag = df['loggflag'][X_train.index]>.3*10**8\n",
    "\n",
    "teff = df['teff'][X_train.index]\n",
    "m_teff = LinearRegression()\n",
    "m_teff.fit(X_train, teff)\n",
    "teff_calc = m_teff.predict(X_train)\n",
    "logg = df['logg'][X_train.index]\n",
    "m_logg = LinearRegression()\n",
    "m_logg.fit(X_train, logg)\n",
    "# m_logg.fit(X_train[~loggflag], logg[~loggflag])\n",
    "logg_calc = m_logg.predict(X_train)\n",
    "X_train['teff'] = teff_calc\n",
    "# X_train['logg'] = logg_calc\n",
    "\n",
    "ind = X_train.index\n",
    "cols = X_train.columns\n",
    "normalizer = StandardScaler()\n",
    "X_train = normalizer.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(\n",
    "    data=X_train,\n",
    "    index=ind,\n",
    "    columns=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ff0c5",
   "metadata": {},
   "source": [
    "### Inspect models for teff & logg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04313a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.loggflag > .6*10**8\n",
    "alpha = .4\n",
    "\n",
    "# mask = (df.magbr3 < df.magar3)*(df.magbr3 > df.magcr3)\n",
    "# alpha = 1\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(20, 20))\n",
    "y_min = min(min(df['logg'][X_use.index]), min(logg_calc))\n",
    "y_max = max(max(df['logg'][X_use.index]), max(logg_calc))\n",
    "axes[0, 0].scatter(df['logg'][X_train.index], logg_calc)\n",
    "axes[0, 0].scatter(df['logg'][X_train.index][mask[X_train.index]], logg_calc[mask[X_train.index]],\n",
    "                   color='r', alpha=alpha)\n",
    "axes[0, 0].set_title('logg from magnitude diffs on the train set')\n",
    "axes[0, 0].set_xlabel('true')\n",
    "axes[0, 0].set_ylabel('predicted')\n",
    "axes[0, 0].plot([y_min, y_max], [y_min, y_max], color='r')\n",
    "\n",
    "axes[0, 1].scatter(df['logg'][X_test.index], m_logg.predict(X_test))\n",
    "axes[0, 1].scatter(df['logg'][X_test.index][mask[X_test.index]], m_logg.predict(X_test)[mask[X_test.index]],\n",
    "                   color='r', alpha=alpha)\n",
    "axes[0, 1].set_title('logg from magnitude diffs on the tet set')\n",
    "axes[0, 1].set_xlabel('true')\n",
    "axes[0, 1].set_ylabel('predicted')\n",
    "axes[0, 1].plot([y_min, y_max], [y_min, y_max], color='r')\n",
    "\n",
    "mask = df.teffflag > 100\n",
    "\n",
    "y_min = min(min(df['teff'][X_use.index]), min(teff_calc))\n",
    "y_max = max(max(df['teff'][X_use.index]), max(teff_calc))\n",
    "axes[1, 0].scatter(df['teff'][X_train.index], teff_calc)\n",
    "axes[1, 0].scatter(df['teff'][X_train.index][mask[X_train.index]], teff_calc[mask[X_train.index]],\n",
    "                   color='r', alpha=alpha)\n",
    "axes[1, 0].set_title('teff from magnitude diffs on the train set')\n",
    "axes[1, 0].set_xlabel('true')\n",
    "axes[1, 0].set_ylabel('predicted')\n",
    "axes[1, 0].plot([y_min, y_max], [y_min, y_max], color='r')\n",
    "\n",
    "axes[1, 1].scatter(df['teff'][X_test.index], m_teff.predict(X_test))\n",
    "axes[1, 1].scatter(df['teff'][X_test.index][mask[X_test.index]], m_teff.predict(X_test)[mask[X_test.index]],\n",
    "                   color='r', alpha=alpha)\n",
    "axes[1, 1].set_title('teff from magnitude diffs on the tet set')\n",
    "axes[1, 1].set_xlabel('true')\n",
    "axes[1, 1].set_ylabel('predicted')\n",
    "axes[1, 1].plot([y_min, y_max], [y_min, y_max], color='r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863ef74e",
   "metadata": {},
   "source": [
    "### Fit & test model for CaFe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b675de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(x):\n",
    "    return (x+.25)**(1/3)\n",
    "\n",
    "def tf_inv(x):\n",
    "    return x**3 - .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0472aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend test set predictors with predicted teff, logg \n",
    "teff_test = m_teff.predict(X_test)\n",
    "logg_test = m_logg.predict(X_test)\n",
    "X_test['teff'] = teff_test\n",
    "# X_test['logg'] = logg_test\n",
    "ind = X_test.index\n",
    "cols = X_test.columns\n",
    "X_test = normalizer.transform(X_test)\n",
    "X_test = pd.DataFrame(\n",
    "    data=X_test,\n",
    "    index=ind,\n",
    "    columns=cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b80c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = False\n",
    "\n",
    "y_train_transformed = tf(y_train) if transform else y_train\n",
    "\n",
    "# nn_model = MLPRegressor(hidden_layer_sizes=(16,), activation='relu', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "# Ca/Fe directly\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(12,), activation='tanh', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "X_train = X_train[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'teff']]\n",
    "X_test = X_test[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'teff']]\n",
    "nn_model.fit(X_train, y_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50136482",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predicted = tf_inv(nn_model.predict(X_train)) if transform else nn_model.predict(X_train)\n",
    "y_test_predicted = tf_inv(nn_model.predict(X_test)) if transform else nn_model.predict(X_test)\n",
    "y_min = min(min(y_train), min(y_test), min(y_train_predicted), min(y_test_predicted))\n",
    "y_max = max(max(y_train), max(y_test), max(y_train_predicted), max(y_test_predicted))\n",
    "# y_min, y_max = -.1, .4\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(10, 10))\n",
    "\n",
    "# axes.grid(True)  # plt.rc('grid', linestyle=':', color='red', linewidth=2)\n",
    "\n",
    "axes.scatter(y_train, y_train_predicted, color='b', alpha=.6, label='train')\n",
    "axes.scatter(y_test, y_test_predicted, color='r', alpha=.6, label='test')\n",
    "axes.plot([y_min, y_max], [y_min, y_max], color='g', linestyle=':')\n",
    "axes.set_xlim([y_min, y_max])\n",
    "axes.set_ylim([y_min, y_max])\n",
    "axes.set_title('True vs. predicted CaFe on train and test set')\n",
    "axes.legend()\n",
    "axes.set_xlabel('true')\n",
    "axes.set_ylabel('predicted')\n",
    "\n",
    "print(f'Mean absolute error on train set: {mean_absolute_error(y_true=y_train, y_pred=y_train_predicted)}')\n",
    "print(f'r2 score on train set: {r2_score(y_true=y_train, y_pred=y_train_predicted)}')\n",
    "\n",
    "print(f'Mean absolute error on test set: {mean_absolute_error(y_true=y_test, y_pred=y_test_predicted)}')\n",
    "print(f'r2 score on test set: {r2_score(y_true=y_test, y_pred=y_test_predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f2c27",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289ba78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "fig, axes = plt.subplots(ncols=2, nrows=1, figsize=(20, 10))\n",
    "\n",
    "axes[0].hist(y_train_predicted-y_train, color='b', bins=25)\n",
    "axes[0].set_title('Error distribution on train set')\n",
    "axes[1].hist(y_test_predicted-y_test, color='r', bins=25)\n",
    "axes[1].set_title('Error distribution on test set')\n",
    "print('Train 16-84 percentile: ', np.percentile(y_train_predicted-y_train, [16, 84]))\n",
    "print('Test 16-84 percentile: ', np.percentile(y_test_predicted-y_test, [16, 84]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac17ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.linspace(start=-0.05, stop=.175, num=10)\n",
    "\n",
    "y_all = pd.concat([y_train, y_test])\n",
    "y_all_predicted = np.concatenate([y_train_predicted, y_test_predicted])\n",
    "\n",
    "xx, yy16, yy84 = [], [], []\n",
    "for i in range(len(steps) - 1):\n",
    "    step = (steps[i] + steps[i+1])/2\n",
    "    xx.append(step)\n",
    "    # yy16.append(np.percentile(y_all_predicted[(y_all>steps[i]) * (y_all<=steps[i+1])]-y_all[(y_all>steps[i]) * (y_all<=steps[i+1])], 16))\n",
    "    # yy84.append(np.percentile(y_all_predicted[(y_all>steps[i]) * (y_all<=steps[i+1])]-y_all[(y_all>steps[i]) * (y_all<=steps[i+1])], 84))\n",
    "    yy16.append(np.percentile(y_all_predicted[(y_all_predicted>steps[i]) * (y_all_predicted<=steps[i+1])]\n",
    "                              - y_all[(y_all_predicted>steps[i]) * (y_all_predicted<=steps[i+1])], 16))\n",
    "    yy84.append(np.percentile(y_all_predicted[(y_all_predicted>steps[i]) * (y_all_predicted<=steps[i+1])]\n",
    "                              - y_all[(y_all_predicted>steps[i]) * (y_all_predicted<=steps[i+1])], 84))\n",
    "\n",
    "y_min = min(min(y_train), min(y_test), min(y_train_predicted), min(y_test_predicted))\n",
    "y_max = max(max(y_train), max(y_test), max(y_train_predicted), max(y_test_predicted))\n",
    "y_min, y_max = -.1, .4 \n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(10, 10))\n",
    "\n",
    "axes.scatter(y_train, y_train_predicted, color='b', alpha=.6, label='train')\n",
    "axes.scatter(y_test, y_test_predicted, color='r', alpha=.6, label='test')\n",
    "axes.plot([y_min, y_max], [y_min, y_max], color='g', linestyle=':')\n",
    "axes.set_xlim([y_min, y_max])\n",
    "axes.set_ylim([y_min, y_max])\n",
    "\n",
    "# Errors\n",
    "# axes.plot(xx, [x0+y0 for x0, y0 in zip(xx, yy16)], color='magenta', label='16th percentile', linewidth=3)\n",
    "# axes.plot(xx, [x0+y0 for x0, y0 in zip(xx, yy84)], color='orange', label='84th percentile', linewidth=3)\n",
    "axes.plot([x0+y0 for x0, y0 in zip(xx, yy16)], xx, color='magenta', label='16th percentile', linewidth=3)\n",
    "axes.plot([x0+y0 for x0, y0 in zip(xx, yy84)], xx, color='orange', label='84th percentile', linewidth=3)\n",
    "\n",
    "axes.set_title('True vs. predicted FeH on train and test set')\n",
    "axes.legend()\n",
    "axes.set_xlabel('true')\n",
    "axes.set_ylabel('predicted')\n",
    "\n",
    "print(f'Mean absolute error on train set: {mean_absolute_error(y_true=y_train, y_pred=y_train_predicted)}')\n",
    "print(f'r2 score on train set: {r2_score(y_true=y_train, y_pred=y_train_predicted)}')\n",
    "\n",
    "print(f'Mean absolute error on test set: {mean_absolute_error(y_true=y_test, y_pred=y_test_predicted)}')\n",
    "print(f'r2 score on test set: {r2_score(y_true=y_test, y_pred=y_test_predicted)}')\n",
    "\n",
    "print('Dataset splitted to 10 chunks, 16-th and 84-th percentile of the error calculated in each chunk and the percentile lines plotted to the graph.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e234078",
   "metadata": {},
   "source": [
    "### CaFe + FeH and combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fee5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sum_train = y_sum[y_train.index]\n",
    "y_sum_test = y_sum[y_test.index]\n",
    "\n",
    "transform = False\n",
    "\n",
    "y_sum_train_transformed = tf(y_sum_train) if transform else y_sum_train\n",
    "\n",
    "# nn_model = MLPRegressor(hidden_layer_sizes=(16,), activation='relu', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "# Ca/Fe directly\n",
    "# nn_model = MLPRegressor(hidden_layer_sizes=(12,), activation='tanh', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "# Ca/Fe + Fe/H\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(9,), activation='relu', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "# Use only for Ca/Fe directly\n",
    "# X_train = X_train[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'teff']]\n",
    "# X_test = X_test[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'teff']]\n",
    "nn_model.fit(X_train, y_sum_train_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sum_train_predicted = tf_inv(nn_model.predict(X_train)) if transform else nn_model.predict(X_train)\n",
    "y_sum_test_predicted = tf_inv(nn_model.predict(X_test)) if transform else nn_model.predict(X_test)\n",
    "y_min = min(min(y_sum_train), min(y_sum_test), min(y_sum_train_predicted), min(y_sum_test_predicted))\n",
    "y_max = max(max(y_sum_train), max(y_sum_test), max(y_sum_train_predicted), max(y_sum_test_predicted))\n",
    "# y_min, y_max = -.1, .4\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(10, 10))\n",
    "\n",
    "# axes.grid(True)  # plt.rc('grid', linestyle=':', color='red', linewidth=2)\n",
    "\n",
    "axes.scatter(y_sum_train, y_sum_train_predicted, color='b', alpha=.6, label='train')\n",
    "axes.scatter(y_sum_test, y_sum_test_predicted, color='r', alpha=.6, label='test')\n",
    "axes.plot([y_min, y_max], [y_min, y_max], color='g', linestyle=':')\n",
    "axes.set_xlim([y_min, y_max])\n",
    "axes.set_ylim([y_min, y_max])\n",
    "axes.set_title('True vs. predicted CaFe on train and test set')\n",
    "axes.legend()\n",
    "axes.set_xlabel('true')\n",
    "axes.set_ylabel('predicted')\n",
    "\n",
    "print(f'Mean absolute error on train set: {mean_absolute_error(y_true=y_sum_train, y_pred=y_sum_train_predicted)}')\n",
    "print(f'r2 score on train set: {r2_score(y_true=y_sum_train, y_pred=y_sum_train_predicted)}')\n",
    "\n",
    "print(f'Mean absolute error on test set: {mean_absolute_error(y_true=y_sum_test, y_pred=y_sum_test_predicted)}')\n",
    "print(f'r2 score on test set: {r2_score(y_true=y_sum_test, y_pred=y_sum_test_predicted)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7614ed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_feh_train = y_sum[y_train.index] - y_train\n",
    "y_feh_test = y_sum[y_test.index] - y_test\n",
    "\n",
    "nn_model = MLPRegressor(hidden_layer_sizes=(9,), activation='logistic', solver='lbfgs', max_iter=4000, random_state=316)\n",
    "#X_train = X_train[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'bpmag_rpmag', 'teff']]\n",
    "#X_test = X_test[['magbr3_magar3', 'magcr3_magbr3', 'jmag_kmag', 'bpmag_rpmag', 'teff']]\n",
    "nn_model.fit(X_train, y_feh_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4f3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_feh_train_predicted = nn_model.predict(X_train)\n",
    "y_feh_test_predicted = nn_model.predict(X_test)\n",
    "y_min = min(min(y_feh_train), min(y_feh_test), min(y_feh_train_predicted), min(y_feh_test_predicted))\n",
    "# y_min = -1\n",
    "y_max = max(max(y_feh_train), max(y_feh_test), max(y_feh_train_predicted), max(y_feh_test_predicted))\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=1, figsize=(10, 10))\n",
    "\n",
    "axes.scatter(y_feh_train, y_feh_train_predicted, color='b', alpha=.6, label='train')\n",
    "axes.scatter(y_feh_test, y_feh_test_predicted, color='r', alpha=.6, label='test')\n",
    "axes.plot([y_min, y_max], [y_min, y_max], color='g', linestyle=':')\n",
    "axes.set_xlim([y_min, y_max])\n",
    "axes.set_ylim([y_min, y_max])\n",
    "axes.set_title('True vs. predicted FeH on train and test set')\n",
    "axes.legend()\n",
    "axes.set_xlabel('true')\n",
    "axes.set_ylabel('predicted')\n",
    "\n",
    "print(f'Mean absolute error on train set: {mean_absolute_error(y_true=y_feh_train, y_pred=y_feh_train_predicted)}')\n",
    "print(f'r2 score on train set: {r2_score(y_true=y_feh_train, y_pred=y_feh_train_predicted)}')\n",
    "\n",
    "print(f'Mean absolute error on test set: {mean_absolute_error(y_true=y_feh_test, y_pred=y_feh_test_predicted)}')\n",
    "print(f'r2 score on test set: {r2_score(y_true=y_feh_test, y_pred=y_feh_test_predicted)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4667b316",
   "metadata": {},
   "source": [
    "#### Combined -- bad :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_sum_train - y_feh_train, y_sum_train_predicted - y_feh_train_predicted)\n",
    "plt.scatter(y_sum_test - y_feh_test, y_sum_test_predicted - y_feh_test_predicted, color='r')\n",
    "plt.plot([-.2, .4], [-.2, .4], color='g')\n",
    "\n",
    "print(r2_score(y_sum_train - y_feh_train, y_sum_train_predicted - y_feh_train_predicted))\n",
    "print(mean_absolute_error(y_sum_train - y_feh_train, y_sum_train_predicted - y_feh_train_predicted))\n",
    "\n",
    "print(r2_score(y_sum_test - y_feh_test, y_sum_test_predicted - y_feh_test_predicted))\n",
    "print(mean_absolute_error(y_sum_test - y_feh_test, y_sum_test_predicted - y_feh_test_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a38565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "242fb8207f97c296f33acf6c366d1e468ec158fb77fc4d51a9c4c6884f3da01a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('p2ch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
